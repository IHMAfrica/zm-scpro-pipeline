name: carepro-pipeline

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.3
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      # allow 4lw queries; not strictly needed for this healthcheck but useful
      ZOOKEEPER_4LW_COMMANDS_WHITELIST: "ruok,stat,mntr,conf,cons,isro"
      # keep heap small for dev machines
      KAFKA_HEAP_OPTS: "-Xms256M -Xmx256M"
    healthcheck:
      # Use zookeeper-shell (shipped in this image) instead of `cub`
      test: ["CMD-SHELL", "zookeeper-shell localhost:2181 ls / >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 60

  kafka:
    image: confluentinc/cp-kafka:7.3.3
    restart: unless-stopped
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"          # Local dev: PLAINTEXT only
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      # simple readiness check without relying on zookeeper utils
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list >/dev/null 2>&1"]
      interval: 10s
      timeout: 10s
      retries: 30
      start_period: 20s

  schema-registry:
    image: confluentinc/cp-schema-registry:7.3.3
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:9092
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    ports:
      - "8082:8081"          # avoid conflict with Flink 8081

  connect:
    image: debezium/connect:2.4
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_started
    ports:
      - "8083:8083"
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: _connect-configs
      OFFSET_STORAGE_TOPIC: _connect-offsets
      STATUS_STORAGE_TOPIC: _connect-status
      KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081

  # postgres:
  #   image: postgres:14
  #   restart: unless-stopped
  #   ports:
  #     - "5432:5432"
  #   environment:
  #     POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
  #     POSTGRES_USER: ${POSTGRES_USER}
  #     POSTGRES_DB: ${POSTGRES_DB}
  #   volumes:
  #     - ./postgres/init:/docker-entrypoint-initdb.d

  flink-jobmanager:
    build:
      context: .
      dockerfile: docker/flink/Dockerfile
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_started
      # postgres:
      #   condition: service_started
    ports:
      - "8081:8081"
    environment:
      JOB_MANAGER_RPC_ADDRESS: flink-jobmanager
      # Kafka & SR
      KAFKA_BOOTSTRAP: kafka:9092
      KAFKA_SECURITY_PROTOCOL: PLAINTEXT
      KAFKA_SASL_MECHANISM: ""
      KAFKA_SASL_USER: ""
      KAFKA_SASL_USERNAME: ""
      KAFKA_SASL_PASSWORD: ""
      SCHEMA_REGISTRY: http://schema-registry:8081
      # Postgres sink
      PG_HOST: host.docker.internal
      PG_PORT: ${PG_PORT}
      PG_DB: ${PG_DB}
      PG_USER: ${PG_USER}
      PG_PASSWORD: ${PG_PASSWORD}
      # Flink tuning
      FLINK_PARALLELISM: ${FLINK_PARALLELISM}
      FLINK_CHECKPOINT_INTERVAL_MS: ${FLINK_CHECKPOINT_INTERVAL_MS}
    command: ["/bin/bash","-lc","/docker-entrypoint.sh jobmanager"]
    volumes:
      - ./flink/job:/opt/flink/usrlib/job:ro

  flink-taskmanager:
    build:
      context: .
      dockerfile: docker/flink/Dockerfile
    restart: unless-stopped
    depends_on:
      flink-jobmanager:
        condition: service_started
    environment:
      JOB_MANAGER_RPC_ADDRESS: flink-jobmanager
      FLINK_PARALLELISM: ${FLINK_PARALLELISM}
    command: ["/bin/bash","-lc","/docker-entrypoint.sh taskmanager"]
    volumes:
      - ./flink/job:/opt/flink/usrlib/job:ro

  # --- Producers (Python) ---
  producer-art:
    image: python:3.10-slim
    restart: unless-stopped
    depends_on:
      - kafka
    working_dir: /app
    command:
      - /bin/bash
      - -lc
      - |
        set -e
        apt-get update && apt-get install -y --no-install-recommends netcat-openbsd && rm -rf /var/lib/apt/lists/*
        pip install --no-cache-dir pymssql==2.2.8 confluent-kafka==2.5.0
        # Split KAFKA_BOOTSTRAP 
        HOST="$${KAFKA_BOOTSTRAP%%:*}"
        PORT="$${KAFKA_BOOTSTRAP##*:}"
        if [ -z "$$PORT" ] || [ "$$PORT" = "$${KAFKA_BOOTSTRAP}" ]; then PORT=9092; fi
        echo "Wait target: $$HOST:$$PORT"
        /bin/wait-for "$$HOST" "$$PORT" 60
        python /app/producer_art.py
    environment:
      SQLSERVER_HOST: ${SQLSERVER_HOST}
      SQLSERVER_PORT: ${SQLSERVER_PORT}
      SQLSERVER_DB: ${SQLSERVER_DB}
      SQLSERVER_USER: ${SQLSERVER_USER}
      SQLSERVER_PASSWORD: ${SQLSERVER_PASSWORD}
      SQLSERVER_TDS_VERSION: ${SQLSERVER_TDS_VERSION}
      KAFKA_BOOTSTRAP: ${KAFKA_BOOTSTRAP}
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL}
      KAFKA_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM}
      KAFKA_SASL_USER: ${KAFKA_SASL_USER}
      KAFKA_SASL_USERNAME: ${KAFKA_SASL_USERNAME}
      KAFKA_SASL_PASSWORD: ${KAFKA_SASL_PASSWORD}
      KAFKA_CLIENT_ID: ${KAFKA_CLIENT_ID}
      KAFKA_COMPRESSION_TYPE: ${KAFKA_COMPRESSION_TYPE}
      KAFKA_TOPIC_ART: ${KAFKA_TOPIC_ART}
      BATCH_SIZE: ${BATCH_SIZE}
      SQL_ART_QUERY_FILE: /sql/art_cohort.sql
    volumes:
      - ./producers:/app:ro
      - ./sql:/sql:ro
      - ./scripts/wait-for.sh:/bin/wait-for:ro

  producer-interactions:
    image: python:3.10-slim
    restart: unless-stopped
    depends_on:
      - kafka
    working_dir: /app
    command:
      - /bin/bash
      - -lc
      - |
        set -e
        apt-get update && apt-get install -y --no-install-recommends netcat-openbsd && rm -rf /var/lib/apt/lists/*
        pip install --no-cache-dir pymssql==2.2.8 confluent-kafka==2.5.0
        HOST="$${KAFKA_BOOTSTRAP%%:*}"
        PORT="$${KAFKA_BOOTSTRAP##*:}"
        if [ -z "$$PORT" ] || [ "$$PORT" = "$${KAFKA_BOOTSTRAP}" ]; then PORT=9092; fi
        echo "Wait target: $$HOST:$$PORT"
        /bin/wait-for "$$HOST" "$$PORT" 60
        python /app/producer_interactions.py
    environment:
      SQLSERVER_HOST: ${SQLSERVER_HOST}
      SQLSERVER_PORT: ${SQLSERVER_PORT}
      SQLSERVER_DB: ${SQLSERVER_DB}
      SQLSERVER_USER: ${SQLSERVER_USER}
      SQLSERVER_PASSWORD: ${SQLSERVER_PASSWORD}
      SQLSERVER_TDS_VERSION: ${SQLSERVER_TDS_VERSION}
      KAFKA_BOOTSTRAP: ${KAFKA_BOOTSTRAP}
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL}
      KAFKA_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM}
      KAFKA_SASL_USER: ${KAFKA_SASL_USER}
      KAFKA_SASL_USERNAME: ${KAFKA_SASL_USERNAME}
      KAFKA_SASL_PASSWORD: ${KAFKA_SASL_PASSWORD}
      KAFKA_CLIENT_ID: ${KAFKA_CLIENT_ID}
      KAFKA_COMPRESSION_TYPE: ${KAFKA_COMPRESSION_TYPE}
      KAFKA_TOPIC_INTERACTIONS: ${KAFKA_TOPIC_INTERACTIONS}
      BATCH_SIZE: ${BATCH_SIZE}
      SQL_INTERACTIONS_QUERY_FILE: /sql/carepro_all_interactions.sql
    volumes:
      - ./producers:/app:ro
      - ./sql:/sql:ro
      - ./scripts/wait-for.sh:/bin/wait-for:ro


  bootstrap:
    image: bash:5.2
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: ["bash","/connectors/topics.sh"]
    environment:
      KAFKA_BOOTSTRAP: kafka:9092
    volumes:
      - ./connectors:/connectors:ro
